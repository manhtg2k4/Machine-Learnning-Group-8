{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13234381,"sourceType":"datasetVersion","datasetId":8387072}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:23.842375Z","iopub.execute_input":"2025-10-03T01:56:23.842900Z","iopub.status.idle":"2025-10-03T01:56:26.586605Z","shell.execute_reply.started":"2025-10-03T01:56:23.842867Z","shell.execute_reply":"2025-10-03T01:56:26.585630Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"![](http:///kaggle/input/animals5-100)","metadata":{}},{"cell_type":"code","source":"# In [1] thư viện\nimport os, re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom glob import glob\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\n# Reproducibility\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\nprint(\"TF version:\", tf.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:26.588239Z","iopub.execute_input":"2025-10-03T01:56:26.588851Z","iopub.status.idle":"2025-10-03T01:56:47.919636Z","shell.execute_reply.started":"2025-10-03T01:56:26.588818Z","shell.execute_reply":"2025-10-03T01:56:47.918574Z"}},"outputs":[{"name":"stderr","text":"2025-10-03 01:56:30.578772: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759456590.875892      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759456590.956636      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"TF version: 2.18.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# In [2] \ndata_root = \"/kaggle/working/animals5-100\"   \nprint(\"Using data_root =\", data_root)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:47.920999Z","iopub.execute_input":"2025-10-03T01:56:47.922858Z","iopub.status.idle":"2025-10-03T01:56:47.927972Z","shell.execute_reply.started":"2025-10-03T01:56:47.922812Z","shell.execute_reply":"2025-10-03T01:56:47.927030Z"}},"outputs":[{"name":"stdout","text":"Using data_root = /kaggle/working/animals5-100\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# In [3]\nfor root, dirs, files in os.walk(data_root):\n    print(\"ROOT:\", root)\n    print(\"  #subdirs:\", len(dirs))\n    print(\"  #files:\", len(files))\n    print(\"  subdirs:\", dirs[:10])\n    print(\"  files:\", files[:10])\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:47.929061Z","iopub.execute_input":"2025-10-03T01:56:47.929398Z","iopub.status.idle":"2025-10-03T01:56:47.956932Z","shell.execute_reply.started":"2025-10-03T01:56:47.929366Z","shell.execute_reply":"2025-10-03T01:56:47.955942Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# In [4]\nIMG_H = 64       # đổi 28/32 để train nhanh hơn; 64 thường OK cho MLP nhỏ\nIMG_W = 64\nBATCH_SIZE = 32\nCOLOR_MODE = 'grayscale'   # 'rgb' nếu bạn muốn dùng màu\nEPOCHS = 25\nprint(\"Config:\", IMG_H, IMG_W, COLOR_MODE, BATCH_SIZE, EPOCHS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:47.959707Z","iopub.execute_input":"2025-10-03T01:56:47.960031Z","iopub.status.idle":"2025-10-03T01:56:47.982152Z","shell.execute_reply.started":"2025-10-03T01:56:47.960009Z","shell.execute_reply":"2025-10-03T01:56:47.981131Z"}},"outputs":[{"name":"stdout","text":"Config: 64 64 grayscale 32 25\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# In [5]\ndatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\n# detect class-folder vs flat\nsubdirs = [d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))]\nhas_class_folders = len(subdirs) > 0 and any(len(os.listdir(os.path.join(data_root, d)))>0 for d in subdirs)\n\nprint(\"Has class folders:\", has_class_folders)\nif has_class_folders:\n    # dataset organized by class folders\n    train_gen = datagen.flow_from_directory(\n        data_root,\n        target_size=(IMG_H, IMG_W),\n        color_mode=COLOR_MODE,\n        batch_size=BATCH_SIZE,\n        class_mode='binary' if len(subdirs)==2 else 'categorical',\n        subset='training',\n        shuffle=True,\n        seed=SEED\n    )\n    val_gen = datagen.flow_from_directory(\n        data_root,\n        target_size=(IMG_H, IMG_W),\n        color_mode=COLOR_MODE,\n        batch_size=BATCH_SIZE,\n        class_mode=train_gen.class_mode,\n        subset='validation',\n        shuffle=False\n    )\nelse:\n    # flat folder: infer label from filename prefix (common pattern: cat.123.jpg or dog_123.jpg)\n    files = [f for f in os.listdir(data_root) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n    if len(files)==0:\n        raise RuntimeError(\"Không tìm thấy file ảnh trong data_root. Kiểm tra đường dẫn.\")\n    def infer_label(fname):\n        m = re.match(r'^([A-Za-z]+)', fname)\n        return m.group(1).lower() if m else 'unknown'\n    df = pd.DataFrame({'filename': files, 'label': [infer_label(f) for f in files]})\n    print(\"Labels sample:\\n\", df['label'].value_counts().head())\n    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=SEED)\n    train_gen = datagen.flow_from_dataframe(train_df, directory=data_root, x_col='filename', y_col='label',\n                                           target_size=(IMG_H, IMG_W), color_mode=COLOR_MODE,\n                                           class_mode='binary' if train_df['label'].nunique()==2 else 'categorical',\n                                           batch_size=BATCH_SIZE, shuffle=True, seed=SEED)\n    val_gen = datagen.flow_from_dataframe(val_df, directory=data_root, x_col='filename', y_col='label',\n                                         target_size=(IMG_H, IMG_W), color_mode=COLOR_MODE,\n                                         class_mode=train_gen.class_mode, batch_size=BATCH_SIZE, shuffle=False)\n\nprint(\"Num classes:\", train_gen.num_classes)\nprint(\"Class indices:\", train_gen.class_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:47.983356Z","iopub.execute_input":"2025-10-03T01:56:47.983672Z","iopub.status.idle":"2025-10-03T01:56:48.378838Z","shell.execute_reply.started":"2025-10-03T01:56:47.983647Z","shell.execute_reply":"2025-10-03T01:56:48.377182Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/361485265.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# detect class-folder vs flat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mhas_class_folders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdirs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/animals5-100'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/animals5-100'","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"# In [6]\nimport matplotlib.pyplot as plt\ndef show_samples(generator, n_per_class=3):\n    # generator phải có attribute class_indices và filepaths\n    classes = list(generator.class_indices.keys())\n    fig, axes = plt.subplots(len(classes), n_per_class, figsize=(n_per_class*2, len(classes)*2))\n    if len(classes)==1:\n        axes = [axes]\n    for i, cls in enumerate(classes):\n        # lấy filepaths thuộc class\n        cls_idx = generator.class_indices[cls]\n        files_cls = [p for p, lbl in zip(generator.filepaths, generator.classes) if lbl==cls_idx]\n        for j in range(n_per_class):\n            if j < len(files_cls):\n                img = plt.imread(files_cls[j])\n                if COLOR_MODE=='grayscale' and img.ndim==3:\n                    img = img[...,0]\n                ax = axes[i][j] if len(classes)>1 else axes[j]\n                ax.imshow(img.squeeze(), cmap='gray' if COLOR_MODE=='grayscale' else None)\n                ax.axis('off')\n                if j==0:\n                    ax.set_ylabel(cls)\n    plt.tight_layout()\n    plt.show()\n\n# show samples (may be slow if many classes)\nshow_samples(val_gen, n_per_class=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:48.379480Z","iopub.status.idle":"2025-10-03T01:56:48.379836Z","shell.execute_reply.started":"2025-10-03T01:56:48.379676Z","shell.execute_reply":"2025-10-03T01:56:48.379692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In [7]\ntry:\n    y_for_weights = train_gen.classes\n    classes_unique = np.unique(y_for_weights)\n    cw_vals = compute_class_weight('balanced', classes=classes_unique, y=y_for_weights)\n    class_weights = dict(zip(classes_unique, cw_vals))\n    print(\"Class weights:\", class_weights)\nexcept Exception as e:\n    class_weights = None\n    print(\"Không thể tính class_weight tự động:\", e)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:48.381322Z","iopub.status.idle":"2025-10-03T01:56:48.381771Z","shell.execute_reply.started":"2025-10-03T01:56:48.381549Z","shell.execute_reply":"2025-10-03T01:56:48.381568Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In [8]\nchannels = 1 if COLOR_MODE=='grayscale' else 3\ninput_shape = (IMG_H, IMG_W, channels)\nnum_classes = train_gen.num_classes\n\nmodel = Sequential([\n    Flatten(input_shape=input_shape),\n    Dense(512, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.3)\n])\n\nif num_classes == 2:\n    model.add(Dense(1, activation='sigmoid'))\n    loss = 'binary_crossentropy'\nelse:\n    model.add(Dense(num_classes, activation='softmax'))\n    loss = 'categorical_crossentropy'\n\nmodel.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:48.384209Z","iopub.status.idle":"2025-10-03T01:56:48.385316Z","shell.execute_reply.started":"2025-10-03T01:56:48.384586Z","shell.execute_reply":"2025-10-03T01:56:48.384603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In [9]\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n    ModelCheckpoint('/kaggle/working/best_mlp_model.h5', save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n]\n\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    class_weight=class_weights\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:48.387668Z","iopub.status.idle":"2025-10-03T01:56:48.388216Z","shell.execute_reply.started":"2025-10-03T01:56:48.388023Z","shell.execute_reply":"2025-10-03T01:56:48.388043Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In [10]\n# Save history to csv\nhist_df = pd.DataFrame(history.history)\nhist_df.to_csv('/kaggle/working/history_mlp.csv', index=False)\nprint(\"Saved history to /kaggle/working/history_mlp.csv\")\n\n# Plot\nplt.figure(figsize=(12,4))\nplt.subplot(1,2,1)\nplt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend(); plt.title('Loss')\n\nplt.subplot(1,2,2)\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend(); plt.title('Accuracy')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:48.389149Z","iopub.status.idle":"2025-10-03T01:56:48.389476Z","shell.execute_reply.started":"2025-10-03T01:56:48.389322Z","shell.execute_reply":"2025-10-03T01:56:48.389335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In [11]\nimport numpy as np\nval_gen.reset()\nsteps = int(np.ceil(val_gen.samples / val_gen.batch_size))\npreds = model.predict(val_gen, steps=steps, verbose=1)\n\nif num_classes == 2:\n    y_pred = (preds.ravel() > 0.5).astype(int)\nelse:\n    y_pred = np.argmax(preds, axis=1)\n\ny_true = val_gen.classes\n\nprint(\"Classification report:\\n\", classification_report(y_true, y_pred, target_names=list(val_gen.class_indices.keys())))\n\ncm = confusion_matrix(y_true, y_pred)\nprint(\"Confusion matrix:\\n\", cm)\n\n# Save predictions to csv\nout_df = pd.DataFrame({\n    'filepath': val_gen.filepaths,\n    'y_true': y_true,\n    'y_pred': y_pred\n})\nout_df.to_csv('/kaggle/working/val_predictions.csv', index=False)\nprint(\"Saved predictions to /kaggle/working/val_predictions.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:48.391998Z","iopub.status.idle":"2025-10-03T01:56:48.392404Z","shell.execute_reply.started":"2025-10-03T01:56:48.392248Z","shell.execute_reply":"2025-10-03T01:56:48.392264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In [12]\nfrom tensorflow.keras.preprocessing import image\nsample_fp = val_gen.filepaths[0]   # bạn có thể đổi index\nprint(\"Sample:\", sample_fp)\nimg = image.load_img(sample_fp, target_size=(IMG_H, IMG_W), color_mode=COLOR_MODE)\nx = image.img_to_array(img) / 255.0\nx = np.expand_dims(x, 0)\npred = model.predict(x)[0]\nif num_classes == 2:\n    prob = float(pred[0])\n    label = list(train_gen.class_indices.keys())[int(prob>0.5)]\n    print(\"Pred:\", label, \"prob:\", prob)\nelse:\n    idx = np.argmax(pred)\n    label = list(train_gen.class_indices.keys())[idx]\n    print(\"Pred:\", label, \"probs:\", pred)\n\nplt.imshow(img.squeeze(), cmap='gray' if COLOR_MODE=='grayscale' else None)\nplt.title(f\"Pred: {label}\")\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:48.394012Z","iopub.status.idle":"2025-10-03T01:56:48.394411Z","shell.execute_reply.started":"2025-10-03T01:56:48.394247Z","shell.execute_reply":"2025-10-03T01:56:48.394269Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# In [13] Optional\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n\nFE_IMG = 224\nfe_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n\nfe_train = fe_datagen.flow_from_directory(data_root, target_size=(FE_IMG,FE_IMG), batch_size=BATCH_SIZE,\n                                          class_mode='categorical' if num_classes>2 else 'binary', subset='training', shuffle=True, seed=SEED)\nfe_val = fe_datagen.flow_from_directory(data_root, target_size=(FE_IMG,FE_IMG), batch_size=BATCH_SIZE,\n                                        class_mode=fe_train.class_mode, subset='validation', shuffle=False, seed=SEED)\n\nbase = MobileNetV2(weights='imagenet', include_top=False, pooling='avg', input_shape=(FE_IMG,FE_IMG,3))\ntrain_feats = base.predict(fe_train, verbose=1)\nval_feats = base.predict(fe_val, verbose=1)\n\n# prepare labels\nif num_classes>2:\n    from tensorflow.keras.utils import to_categorical\n    y_train = to_categorical(fe_train.classes, num_classes)\n    y_val = to_categorical(fe_val.classes, num_classes)\nelse:\n    y_train = fe_train.classes\n    y_val = fe_val.classes\n\nclf = Sequential([\n    Dense(256, activation='relu', input_shape=(train_feats.shape[1],)),\n    Dropout(0.5),\n    Dense(128, activation='relu'),\n    Dense(num_classes if num_classes>2 else 1, activation='softmax' if num_classes>2 else 'sigmoid')\n])\nclf.compile(optimizer='adam', loss='categorical_crossentropy' if num_classes>2 else 'binary_crossentropy', metrics=['accuracy'])\nclf.fit(train_feats, y_train, validation_data=(val_feats, y_val), epochs=15, batch_size=32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T01:56:48.395945Z","iopub.status.idle":"2025-10-03T01:56:48.396440Z","shell.execute_reply.started":"2025-10-03T01:56:48.396243Z","shell.execute_reply":"2025-10-03T01:56:48.396259Z"}},"outputs":[],"execution_count":null}]}